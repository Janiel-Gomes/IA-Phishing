# ğŸ›¡ï¸ IA-Phishing â€” Detector Multimodal de Phishing com IA

[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-000000?style=for-the-badge&logo=flask&logoColor=white)](https://flask.palletsprojects.com/)
[![LangChain](https://img.shields.io/badge/LangChain-121212?style=for-the-badge&logo=chainlink&logoColor=white)](https://www.langchain.com/)

O **IA-Phishing** Ã© um sistema avanÃ§ado de detecÃ§Ã£o de fraudes digitais que utiliza inteligÃªncia artificial multimodal para analisar links, e-mails, cÃ³digo HTML e imagens. O projeto foca em **portabilidade** (IA Local) e **explicabilidade**, ajudando o usuÃ¡rio a entender por que um conteÃºdo foi classificado como malicioso.

---

## ğŸ¯ DescriÃ§Ã£o do Problema e SoluÃ§Ã£o

### Problema
O phishing moderno Ã© complexo. Atacantes nÃ£o usam apenas URLs falsas; eles usam engenharia social agressiva, sites com design idÃªntico ao real e tÃ©cnicas de obscurecimento de cÃ³digo. Analisadores simples de URL falham ao ignorar o contexto visual e textual.

### SoluÃ§Ã£o
Nossa soluÃ§Ã£o implementa uma **Arquitetura Multi-Agente**. Ao processar um input, o sistema dispara mÃºltiplos agentes especializados (LÃ©xico, SSL, NLP e VisÃ£o) que trabalham em paralelo. O resultado Ã© consolidado por um orquestrador que gera um veredito baseado em pesos ponderados e fornece um chat interativo para tirar dÃºvidas tÃ©cnicas.

---

## ğŸ§  Arquitetura de LLM

O fluxo de processamento segue o padrÃ£o moderno de engenharia de LLM:

```mermaid
graph LR
    Input[Input do UsuÃ¡rio] --> Prompt[Prompt Template]
    Prompt --> RAG[RecuperaÃ§Ã£o RAG]
    RAG --> Model[LLM: Ollama/OpenAI]
    Model --> Pydantic[Structured Output]
    Pydantic --> Result[Resultado no Dashboard]
    Result --> Chat[Chat ExplanatÃ³rio]
```

1.  **Input**: URL, Texto, HTML ou Imagem.
2.  **Orquestrador**: Divide a tarefa entre agentes.
3.  **Prompt & RAG**: Agentes NLP e Chat injetam conhecimento tÃ©cnico da base de dados local via VectorStore.
4.  **Modelos**: O sistema decide entre usar **IA Local (Privacidade)** ou **IA Cloud (PotÃªncia)**.
5.  **Structured Output**: Usamos Pydantic para garantir que o modelo responda EXATAMENTE no formato que o sistema espera.

---

## ğŸ› ï¸ DecisÃµes de Engenharia e Justificativas

| DecisÃ£o | Escolha | Justificativa |
|---------|---------|---------------|
| **Framework** | **LangChain** | AbstraÃ§Ã£o poderosa para trocar de provedor de IA (Ollama/OpenAI) sem refatorar o backend. Suporte nativo para RAG e Cadeias de Chat. |
| **Modelos** | **HÃ­brido (Qwen/GPT-4o)** | Usamos modelos locais de 0.5B para rapidez e privacidade em texto. Usamos GPT-4o para visÃ£o devido Ã  superioridade na anÃ¡lise de imagens. |
| **Temperatura** | **0.0** | Em seguranÃ§a, a "criatividade" Ã© um risco. Precisamos de respostas determinÃ­sticas e tÃ©cnicas; a mesma evidÃªncia deve gerar o mesmo veredito. |
| **Prompting** | **Chain-of-Thought** | Prompts estruturados que guiam a IA a analisar primeiro o "O que" (fatos) e depois o "Por que" (razÃ£o) antes do "Veredito" (decisÃ£o). |
| **Tools** | **Pydantic Parser** | Tratamos a saÃ­da estruturada da IA como a ferramenta principal de integraÃ§Ã£o com o banco de dados SQLite. |

---

## âœ… O que Funcionou
- **ConsolidaÃ§Ã£o em Paralelo**: O uso de `ThreadPoolExecutor` reduziu o tempo de anÃ¡lise de 10s para menos de 3s.
- **RAG (Knowledge Base)**: O chat deixou de dar respostas genÃ©ricas e passou a citar tÃ©cnicas reais de phishing encontradas na base de conhecimento.
- **Persistence**: O uso de `localStorage` para manter o tema e o modelo preferido melhorou drasticamente a usabilidade (UX).

## âŒ O que NÃ£o Funcionou e LimitaÃ§Ãµes
- **VisÃ£o Local em CPUs**: O modelo Llava via Ollama apresentou tempos de resposta de >40s em hardware domÃ©stico, inviabilizando o uso local para imagens (por isso mantivemos GPT-4o para o modo Vision).
- **Falsos Positivos em URLs Curtas**: Links encurtados (bit.ly) Ã s vezes geram scores altos no analisador lÃ©xico sem serem maliciosos, exigindo a anÃ¡lise de texto para equilibrar o score.

---

## ğŸš€ Como Executar
1. Instale o Ollama: `ollama run qwen2.5:0.5b`
2. Instale as dependÃªncias: `pip install -r requirements.txt`
3. Inicie o servidor: `python app.py`
4. Acesse: `http://127.0.0.1:7865`

---
> **Aviso AcadÃªmico**: Este Ã© um projeto educativo. NÃ£o deve ser utilizado como Ãºnica ferramenta de seguranÃ§a em ambientes de produÃ§Ã£o.
